{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AE설명 : http://solarisailab.com/archives/113\n",
    "- VAE : http://nolsigan.com/blog/what-is-variational-autoencoder/\n",
    "- Auto-Encoding Variational Bayes : https://arxiv.org/abs/1312.6114  [[code](https://github.com/ikostrikov/TensorFlow-VAE-GAN-DRAW)]\n",
    "- Tutorial on Variational Autoencoders : https://arxiv.org/abs/1606.05908\n",
    "- GAN : http://aliensunmin.github.io/project/accv16tutorial/media/generative.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-04-11 18:07:58--  http://data/\n",
      "Resolving data... 127.0.53.53\n",
      "Connecting to data|127.0.53.53|:80... failed: Operation timed out.\n",
      "Retrying.\n",
      "\n",
      "--2017-04-11 18:09:14--  (try: 2)  http://data/\n",
      "Connecting to data|127.0.53.53|:80... failed: Operation timed out.\n",
      "Retrying.\n",
      "\n",
      "--2017-04-11 18:10:31--  (try: 3)  http://data/\n",
      "Connecting to data|127.0.53.53|:80... failed: Operation timed out.\n",
      "Retrying.\n",
      "\n",
      "--2017-04-11 18:11:50--  (try: 4)  http://data/\n",
      "Connecting to data|127.0.53.53|:80... failed: Operation timed out.\n",
      "Retrying.\n",
      "\n",
      "--2017-04-11 18:13:09--  (try: 5)  http://data/\n",
      "Connecting to data|127.0.53.53|:80... ^C\n"
     ]
    }
   ],
   "source": [
    "!wget -p data/ -c http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gzip -d data/mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "import os\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_dataset():\n",
    "    dataset = pickle.load(open('data/mnist.pkl','rb'))\n",
    "    train_set_x = numpy.concatenate((dataset[0][0],dataset[1][0]),axis=0)\n",
    "    train_set_y = numpy.concatenate((dataset[0][1],dataset[1][1]),axis=0)\n",
    "    return ((train_set_x,train_set_y),(dataset[2][0],dataset[2][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _shared_dataset(data_xy):\n",
    "    data_x, data_y = data_xy\n",
    "    shared_x = theano.shared(numpy.asarray(data_x,\n",
    "                                           dtype=theano.config.floatX), borrow=True)\n",
    "    shared_y = theano.shared(numpy.asarray(data_y,\n",
    "                                           dtype='int32'), borrow=True)\n",
    "    return shared_x, shared_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_full():\n",
    "    dataset = load_mnist_dataset()\n",
    "\n",
    "    train_set_x, train_set_y = dataset[0]\n",
    "    test_set_x, test_set_y = dataset[1]\n",
    "\n",
    "    train_set_x, train_set_y = _shared_dataset((train_set_x, train_set_y))\n",
    "    test_set_x, test_set_y = _shared_dataset((test_set_x, test_set_y))\n",
    "\n",
    "    return [(train_set_x, train_set_y), (test_set_x, test_set_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_for_validation(n_v = 10000):\n",
    "    dataset = load_mnist_dataset()\n",
    "\n",
    "    train_set_x, train_set_y = dataset[0]\n",
    "\n",
    "    randix = numpy.random.permutation(train_set_x.shape[0])\n",
    "\n",
    "    valid_set_x = train_set_x[randix[:n_v]]\n",
    "    valid_set_y = train_set_y[randix[:n_v]]\n",
    "    train_set_x = train_set_x[randix[n_v:]]\n",
    "    train_set_y = train_set_y[randix[n_v:]]\n",
    "\n",
    "    train_set_x, train_set_y = _shared_dataset((train_set_x, train_set_y))\n",
    "    valid_set_x, valid_set_y = _shared_dataset((valid_set_x, valid_set_y))\n",
    "\n",
    "    return [(train_set_x, train_set_y), (valid_set_x, valid_set_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_mnist_for_semi_sup(n_l=1000, n_v=1000):\n",
    "    dataset = load_mnist_dataset()\n",
    "\n",
    "    _train_set_x, _train_set_y = dataset[0]\n",
    "\n",
    "    rand_ind = numpy.random.permutation(_train_set_x.shape[0])\n",
    "    _train_set_x = _train_set_x[rand_ind]\n",
    "    _train_set_y = _train_set_y[rand_ind]\n",
    "\n",
    "    s_c = n_l / 10.0\n",
    "    train_set_x = numpy.zeros((n_l, 28 ** 2))\n",
    "    train_set_y = numpy.zeros(n_l)\n",
    "    for i in range(10):\n",
    "        ind = numpy.where(_train_set_y == i)[0]\n",
    "        train_set_x[i * s_c:(i + 1) * s_c, :] = _train_set_x[ind[0:s_c], :]\n",
    "        train_set_y[i * s_c:(i + 1) * s_c] = _train_set_y[ind[0:s_c]]\n",
    "        _train_set_x = numpy.delete(_train_set_x, ind[0:s_c], 0)\n",
    "        _train_set_y = numpy.delete(_train_set_y, ind[0:s_c])\n",
    "\n",
    "    print(rand_ind)\n",
    "    rand_ind = numpy.random.permutation(train_set_x.shape[0])\n",
    "    train_set_x = train_set_x[rand_ind]\n",
    "    train_set_y = train_set_y[rand_ind]\n",
    "    valid_set_x = _train_set_x[:n_v]\n",
    "    valid_set_y = _train_set_y[:n_v]\n",
    "    # ul_train_set_x = _train_set_x[n_v:]\n",
    "    train_set_ul_x = numpy.concatenate((train_set_x, _train_set_x[n_v:]), axis=0)\n",
    "    train_set_ul_x = train_set_ul_x[numpy.random.permutation(train_set_ul_x.shape[0])]\n",
    "    ul_train_set_y = _train_set_y[n_v:]  # dummy\n",
    "\n",
    "    train_set_x, train_set_y = _shared_dataset((train_set_x, train_set_y))\n",
    "    train_set_ul_x, ul_train_set_y = _shared_dataset((train_set_ul_x, ul_train_set_y))\n",
    "    valid_set_x, valid_set_y = _shared_dataset((valid_set_x, valid_set_y))\n",
    "\n",
    "    return [(train_set_x, train_set_y, train_set_ul_x), (valid_set_x, valid_set_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
