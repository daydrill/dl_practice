{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/01_pure_seq2seq.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# TensorFlow of Course :)\n",
    "import tensorflow as tf\n",
    "\n",
    "# The paths of RNNCell or rnn functions are too long.\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops import *\n",
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.legacy_seq2seq import rnn_decoder, \\\n",
    "embedding_rnn_decoder, \\\n",
    "embedding_rnn_seq2seq, \\\n",
    "attention_decoder, embedding_attention_decoder, \\\n",
    "embedding_attention_seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi this is Jaemin.',\n",
       " 'Nice to meet you too!',\n",
       " 'I like Python.',\n",
       " 'Bye Bye.',\n",
       " 'I live in Seoul, South Korea.',\n",
       " 'I study industrial engineering.',\n",
       " 'Beer please!',\n",
       " 'Leffe brown!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "all_target_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    word2id = dict()\n",
    "    id2word = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        word2id['_GO'] = 0\n",
    "        word2id['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            word2id[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        word2id['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            word2id[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in word2id.items():\n",
    "        id2word[value] = key\n",
    "            \n",
    "    return word2id, id2word, max_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 3,\n",
      "  ',': 20,\n",
      "  '.': 2,\n",
      "  'Beer': 26,\n",
      "  'Bye': 5,\n",
      "  'Hi': 6,\n",
      "  'I': 4,\n",
      "  'Jaemin': 9,\n",
      "  'Korea': 22,\n",
      "  'Leffe': 28,\n",
      "  'Nice': 10,\n",
      "  'Python': 16,\n",
      "  'Seoul': 19,\n",
      "  'South': 21,\n",
      "  '_GO': 0,\n",
      "  '_PAD': 1,\n",
      "  'brown': 29,\n",
      "  'engineering': 25,\n",
      "  'in': 18,\n",
      "  'industrial': 24,\n",
      "  'is': 8,\n",
      "  'like': 15,\n",
      "  'live': 17,\n",
      "  'meet': 12,\n",
      "  'please': 27,\n",
      "  'study': 23,\n",
      "  'this': 7,\n",
      "  'to': 11,\n",
      "  'too': 14,\n",
      "  'you': 13},\n",
      " {0: '_GO',\n",
      "  1: '_PAD',\n",
      "  2: '.',\n",
      "  3: '!',\n",
      "  4: 'I',\n",
      "  5: 'Bye',\n",
      "  6: 'Hi',\n",
      "  7: 'this',\n",
      "  8: 'is',\n",
      "  9: 'Jaemin',\n",
      "  10: 'Nice',\n",
      "  11: 'to',\n",
      "  12: 'meet',\n",
      "  13: 'you',\n",
      "  14: 'too',\n",
      "  15: 'like',\n",
      "  16: 'Python',\n",
      "  17: 'live',\n",
      "  18: 'in',\n",
      "  19: 'Seoul',\n",
      "  20: ',',\n",
      "  21: 'South',\n",
      "  22: 'Korea',\n",
      "  23: 'study',\n",
      "  24: 'industrial',\n",
      "  25: 'engineering',\n",
      "  26: 'Beer',\n",
      "  27: 'please',\n",
      "  28: 'Leffe',\n",
      "  29: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_word2id, enc_id2word, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_word2id, dec_id2word, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, enc_word2id[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2ids(sent, vocab, max_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [vocab[token] for token in tokens] + [1] * pad_length\n",
    "    else:\n",
    "        return [vocab[token] for token in tokens] + [0] * pad_length, current_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "[0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2ids('Hi What is your name?', vocab=enc_word2id, max_sentence_length=enc_sentence_length, is_target=False))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2ids('Hi this is Jaemin.', vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ids2sent(ids, reverse_vocab):\n",
    "    return \" \".join([reverse_vocab[i] for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2sent([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], reverse_vocab=dec_id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 2000\n",
    "n_enc_layer = 3\n",
    "n_dec_layer = 3\n",
    "hidden_size = 30\n",
    "\n",
    "enc_emb_size = 30 #enc_vocab_size\n",
    "dec_emb_size = 30 # dec_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch major => time major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, perm=[1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, perm=[1,0])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    enc_Wemb = tf.get_variable('enc_word_emb',\n",
    "        initializer=tf.random_uniform([enc_vocab_size+1, enc_emb_size]))\n",
    "    dec_Wemb = tf.get_variable('dec_word_emb',\n",
    "        initializer=tf.random_uniform([dec_vocab_size+2, dec_emb_size]))\n",
    "    dec_out_W = tf.get_variable('dec_out_W',\n",
    "        initializer=tf.random_uniform([hidden_size, dec_vocab_size+2]))\n",
    "    dec_out_b = tf.get_variable('dec_out_b',\n",
    "        initializer=tf.random_uniform([dec_vocab_size+2]))\n",
    "    \n",
    "with tf.variable_scope('encoder'):\n",
    "    enc_emb_inputs = tf.nn.embedding_lookup(enc_Wemb, enc_inputs_t)\n",
    "    \n",
    "    # enc_emb_inputs:\n",
    "    #     list(enc_sent_len) of tensor[batch_size x embedding_size]\n",
    "    # Because `static_rnn` takes list inputs\n",
    "    enc_emb_inputs = tf.unstack(enc_emb_inputs)\n",
    "    \n",
    "    enc_cell = BasicRNNCell(hidden_size)\n",
    "    \n",
    "    # enc_sent_len x batch_size x embedding_size\n",
    "    enc_outputs, enc_last_state = tf.contrib.rnn.static_rnn(\n",
    "        cell=enc_cell,\n",
    "        inputs=enc_emb_inputs,\n",
    "        sequence_length=sequence_lengths,\n",
    "        dtype=tf.float32)\n",
    "\n",
    "dec_outputs = []\n",
    "dec_predictions = []\n",
    "with tf.variable_scope('decoder') as scope:\n",
    "    dec_cell = BasicRNNCell(hidden_size)\n",
    "    \n",
    "    for i in range(dec_sentence_length+1):\n",
    "        if i == 0:\n",
    "            input_ = tf.nn.embedding_lookup(dec_Wemb, dec_inputs_t[i])\n",
    "            state = enc_last_state\n",
    "        else:\n",
    "            scope.reuse_variables()\n",
    "            input_ = tf.nn.embedding_lookup(dec_Wemb, dec_prediction)\n",
    "        \n",
    "        # dec_output: batch_size x dec_vocab_size+2\n",
    "        # state:      batch_size x hidden_size\n",
    "        dec_output, state = dec_cell(input_, state)\n",
    "        dec_output = tf.nn.xw_plus_b(dec_output, dec_out_W, dec_out_b)\n",
    "        \n",
    "        # dec_prediction: batch_size x 1\n",
    "        dec_prediction = tf.argmax(dec_output, axis=1)\n",
    "        \n",
    "        dec_outputs.append(dec_output)\n",
    "        dec_predictions.append(dec_prediction)\n",
    "\n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.stack(dec_predictions), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "        \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  to industrial too too too too too too too too too\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  to Korea too too too too too too too too too\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  too is too too too too too too too too too\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  too industrial too too too too too too too too too\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  too is too too too too too too too too too\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  to I too too too too too too too too too\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  to meet too too too too too too too too too\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  to industrial too too too too too too too too too\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 15.64\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I please ! engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO I to ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I please ! engineering . ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO I please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO I to ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 4.45\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I this is . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice this industrial you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I please ! . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I please Python engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 2.25\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.75\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJQAAAJfCAYAAAApVYwIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12546d0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(n_epoch * batch_size), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_Proj_Emb_Wrapper\n",
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/02_Proj_Emb_Wrapper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch major => time major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, perm=[1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, perm=[1,0])\n",
    "\n",
    "with tf.variable_scope('encoder'):\n",
    "    enc_cell = BasicRNNCell(hidden_size)\n",
    "    enc_cell = EmbeddingWrapper(enc_cell, enc_vocab_size+1, enc_emb_size)\n",
    "    \n",
    "    # enc_sent_len x batch_size x embedding_size\n",
    "    enc_outputs, enc_last_state = tf.contrib.rnn.static_rnn(\n",
    "        cell=enc_cell,\n",
    "        inputs=tf.unstack(enc_inputs_t), \n",
    "        sequence_length=sequence_lengths,\n",
    "        dtype=tf.float32)\n",
    "\n",
    "dec_outputs = []\n",
    "dec_predictions = []\n",
    "with tf.variable_scope('decoder') as scope:\n",
    "    dec_cell = BasicRNNCell(hidden_size)\n",
    "    dec_cell = EmbeddingWrapper(dec_cell, dec_vocab_size+2, dec_emb_size)\n",
    "    dec_cell = OutputProjectionWrapper(dec_cell, dec_vocab_size+2)\n",
    "    \n",
    "    for i in range(dec_sentence_length+1):\n",
    "        if i == 0:\n",
    "            input_ = dec_inputs_t[i]\n",
    "            state = enc_last_state\n",
    "        else:\n",
    "            scope.reuse_variables()\n",
    "            input_ = dec_prediction\n",
    "        \n",
    "        # dec_output: batch_size x dec_vocab_size+2\n",
    "        # state:      batch_size x hidden_size\n",
    "        dec_output, state = dec_cell(input_, state)\n",
    "        \n",
    "        # dec_prediction: batch_size x 1\n",
    "        dec_prediction = tf.argmax(dec_output, axis=1)\n",
    "        \n",
    "        dec_outputs.append(dec_output)\n",
    "        dec_predictions.append(dec_prediction)\n",
    "\n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.stack(dec_predictions), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "        \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  Hi please South too ! brown please South too ! brown\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  Hi please South too ! brown please South too ! brown\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  live _GO Hi like Python Hi please South too ! brown\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  study too ! ! I _PAD South too ! brown please\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  live _GO Hi like this . Hi please South too !\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  live _GO Hi like Python Hi please South too ! brown\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  live _GO Hi like Python Hi please South too ! brown\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  Hi like Python Hi please South too ! brown please South\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 14.54\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I to _GO I _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like ! . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO I like ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I like ! . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO I _PAD ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO I brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 4.92\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi to meet _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I study ! . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live meet Seoul too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study in . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO I brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 2.92\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.98\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_rnn_decoder\n",
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/03_rnn_decoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _extract_argmax_and_embed(embedding,\n",
    "                              output_projection=None,\n",
    "                              update_embedding=True):\n",
    "    \"\"\"Get a loop_function that extracts the previous symbol and embeds it.\n",
    "    Args:\n",
    "    embedding: embedding tensor for symbols.\n",
    "    output_projection: None or a pair (W, B). If provided, each fed previous\n",
    "      output will first be multiplied by W and added B.\n",
    "    update_embedding: Boolean; if False, the gradients will not propagate\n",
    "      through the embeddings.\n",
    "      Returns:\n",
    "      A loop function.\n",
    "      \"\"\"\n",
    "    def loop_function(prev, _):\n",
    "        if output_projection is not None:\n",
    "            prev = tf.nn.xw_plus_b(prev, output_projection[0], output_projection[1])\n",
    "        prev_symbol = tf.argmax(prev, 1)\n",
    "        # Note that gradients will not propagate through the second parameter of\n",
    "        # embedding_lookup.\n",
    "        emb_prev = tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "        if not update_embedding:\n",
    "            emb_prev = tf.stop_gradient(emb_prev)\n",
    "        return emb_prev\n",
    "\n",
    "    return loop_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch_major => time_major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, [1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, [1,0])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    dec_Wemb = tf.get_variable('dec_word_emb',\n",
    "        initializer=tf.random_uniform([dec_vocab_size+2, dec_emb_size]))\n",
    "    \n",
    "with tf.variable_scope('encoder'):\n",
    "    enc_cell = BasicRNNCell(hidden_size)\n",
    "    enc_cell = EmbeddingWrapper(enc_cell, enc_vocab_size+1, enc_emb_size)\n",
    "    \n",
    "    # enc_sent_len x batch_size x embedding_size\n",
    "    enc_outputs, enc_last_state = tf.contrib.rnn.static_rnn(\n",
    "        cell=enc_cell,\n",
    "        inputs=tf.unstack(enc_inputs_t),\n",
    "        sequence_length=sequence_lengths,\n",
    "        dtype=tf.float32)\n",
    "\n",
    "dec_outputs = []\n",
    "dec_predictions = []\n",
    "with tf.variable_scope('decoder'):\n",
    "    dec_cell = BasicRNNCell(hidden_size)\n",
    "    dec_cell = OutputProjectionWrapper(dec_cell, dec_vocab_size+2)\n",
    "    \n",
    "    # EmbeddingWrapper & tf.unstack(dec_inputs_t) raises dimension error\n",
    "    dec_emb_inputs = tf.nn.embedding_lookup(dec_Wemb, dec_inputs_t)\n",
    "    \n",
    "    # dec_outputs: [dec_sent_len+1 x batch_size x hidden_size]\n",
    "    dec_outputs, dec_last_state = rnn_decoder(\n",
    "        decoder_inputs = tf.unstack(dec_emb_inputs),\n",
    "        initial_state = enc_last_state,\n",
    "        cell = dec_cell,\n",
    "        loop_function = _extract_argmax_and_embed(dec_Wemb))\n",
    "\n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.argmax(tf.stack(dec_outputs), axis=-1), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO ! to to to to to to to to to\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  . ! to to to to to to to to to\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO ! to to to to to to to to to\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _PAD ! to to to to to to to to to\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  I _PAD ! to to to to to to to to\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO ! study to to to to to to to to\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO ! study to to to to to to to to\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  Nice study to to to to to to to to to\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 12.70\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I live is engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice this Bye . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I this is engineering . . _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I please ! . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO I please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 4.35\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I this is engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like ! . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in engineering , South . . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study is engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 2.48\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 1.08\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_embedding_rnn_decoder.ipynb\n",
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/04_embedding_rnn_decoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch_major => time_major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, [1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, [1,0])\n",
    "    \n",
    "with tf.variable_scope('encoder'):\n",
    "    enc_cell = BasicRNNCell(hidden_size)\n",
    "    enc_cell = EmbeddingWrapper(enc_cell, enc_vocab_size+1, enc_emb_size)\n",
    "    \n",
    "    # enc_sent_len x batch_size x embedding_size\n",
    "    enc_outputs, enc_last_state = tf.contrib.rnn.static_rnn(\n",
    "        cell=enc_cell,\n",
    "        inputs=tf.unstack(enc_inputs_t),\n",
    "        sequence_length=sequence_lengths,\n",
    "        dtype=tf.float32)\n",
    "\n",
    "dec_outputs = []\n",
    "dec_predictions = []\n",
    "with tf.variable_scope('decoder'):\n",
    "    dec_cell = BasicRNNCell(hidden_size)\n",
    "    dec_cell = OutputProjectionWrapper(dec_cell, dec_vocab_size+2)\n",
    "    \n",
    "    # dec_outputs: [dec_sent_len+1 x batch_size x hidden_size]\n",
    "    dec_outputs, dec_last_state = embedding_rnn_decoder(\n",
    "        decoder_inputs=tf.unstack(dec_inputs_t),\n",
    "        initial_state=enc_last_state,\n",
    "        cell=dec_cell,\n",
    "        num_symbols=dec_vocab_size+2,\n",
    "        embedding_size=dec_emb_size,\n",
    "        feed_previous=True)\n",
    "\n",
    "        \n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.argmax(tf.stack(dec_outputs), axis=-1), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "        \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  like Nice Python study . Korea Jaemin meet study Nice Nice\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  Seoul ! _PAD Leffe too _GO Jaemin ! to I ,\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  like Beer _GO brown South Seoul _GO industrial brown live please\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  Bye Nice _GO study ! Seoul brown live Jaemin Seoul to\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  like like _GO brown too too Nice Nice _PAD _PAD Leffe\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  Seoul brown live you _PAD Leffe to Jaemin Seoul Jaemin !\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  like like _GO brown too too Nice Nice _PAD _PAD Leffe\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  please in is is South , this meet Python engineering Beer\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 13.69\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO _GO I is . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to Jaemin . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I study Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I study in Seoul , South . . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study in . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO I please _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO I _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 3.99\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I study Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I study in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial . . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO I please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 1.83\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.46\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_embedding_rnn_seq2seq\n",
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/05_embedding_rnn_seq2seq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch_major => time_major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, [1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, [1,0])\n",
    "\n",
    "rnn_cell = BasicRNNCell(hidden_size)\n",
    "\n",
    "with tf.variable_scope(\"embedding_rnn_seq2seq\"):\n",
    "    # dec_outputs: [dec_sent_len+1 x batch_size x hidden_size]\n",
    "    dec_outputs, dec_last_state = embedding_rnn_seq2seq(\n",
    "        encoder_inputs=tf.unstack(enc_inputs_t),\n",
    "        decoder_inputs=tf.unstack(dec_inputs_t),\n",
    "        cell=rnn_cell,\n",
    "        num_encoder_symbols=enc_vocab_size+1,\n",
    "        num_decoder_symbols=dec_vocab_size+2,\n",
    "        embedding_size=enc_emb_size,\n",
    "        feed_previous=True)\n",
    "\n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.argmax(tf.stack(dec_outputs), axis=-1), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "        \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  Beer is , South meet Hi , Leffe Nice ! Nice\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  Beer is , South , Leffe Nice ! Nice ! Nice\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  Jaemin is , South , Leffe Nice ! Nice ! Nice\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  Beer is , study Nice ! _PAD like Bye in please\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  Beer Hi , Leffe Nice ! Nice ! Nice ! Nice\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  Beer Hi , Hi too to Hi Leffe Leffe Beer study\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  Jaemin is , South , Leffe Nice ! Nice ! Nice\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  Beer is , South , Leffe Nice ! Nice ! Nice\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 13.33\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I like is you _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I like is you . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO I like . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I like is you , you _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I like is you _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO I like _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO I like _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 4.42\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I like is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I to in you , ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO I Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I to in you , South _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I like is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO I Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO I Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 3.06\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO I study is engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I to in you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer Bye ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 1.77\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_attention_decoder\n",
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/06_attention_decoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _extract_argmax_and_embed(embedding,\n",
    "                              output_projection=None,\n",
    "                              update_embedding=True):\n",
    "    \"\"\"Get a loop_function that extracts the previous symbol and embeds it.\n",
    "    Args:\n",
    "    embedding: embedding tensor for symbols.\n",
    "    output_projection: None or a pair (W, B). If provided, each fed previous\n",
    "      output will first be multiplied by W and added B.\n",
    "    update_embedding: Boolean; if False, the gradients will not propagate\n",
    "      through the embeddings.\n",
    "      Returns:\n",
    "      A loop function.\n",
    "      \"\"\"\n",
    "    def loop_function(prev, _):\n",
    "        if output_projection is not None:\n",
    "            prev = tf.nn.xw_plus_b(prev, output_projection[0], output_projection[1])\n",
    "        prev_symbol = tf.argmax(prev, 1)\n",
    "        # Note that gradients will not propagate through the second parameter of\n",
    "        # embedding_lookup.\n",
    "        emb_prev = tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "        if not update_embedding:\n",
    "            emb_prev = tf.stop_gradient(emb_prev)\n",
    "        return emb_prev\n",
    "\n",
    "    return loop_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch_major => time_major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, [1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, [1,0])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    dec_Wemb = tf.get_variable('dec_word_emb',\n",
    "        initializer=tf.random_uniform([dec_vocab_size+2, dec_emb_size]))\n",
    "    \n",
    "with tf.variable_scope('encoder'):\n",
    "    enc_cell = BasicRNNCell(hidden_size)\n",
    "    enc_cell = EmbeddingWrapper(enc_cell, enc_vocab_size+1, enc_emb_size)\n",
    "    \n",
    "    # enc_sent_len x batch_size x embedding_size\n",
    "    enc_outputs, enc_last_state = tf.contrib.rnn.static_rnn(\n",
    "        cell=enc_cell,\n",
    "        inputs=tf.unstack(enc_inputs_t),\n",
    "        sequence_length=sequence_lengths,\n",
    "        dtype=tf.float32)\n",
    "\n",
    "top_states = []\n",
    "with tf.variable_scope('attention'):\n",
    "    # top_states: enc_sent_len x [batch_size x 1 x embedding_size]\n",
    "    #           list of enc_output of each encoder step\n",
    "    # enc_outputs has length of enc_sent_len (= max_enc_len)\n",
    "    for enc_output in enc_outputs:\n",
    "        top_states.append(tf.reshape(enc_output, [-1, 1, enc_cell.output_size]))\n",
    "\n",
    "    # attention_states: [batch_size x enc_sent_len x embedding_size]\n",
    "    attention_states = tf.concat(top_states, 1)\n",
    "    \n",
    "dec_outputs = []\n",
    "dec_predictions = []\n",
    "with tf.variable_scope('decoder'):\n",
    "    dec_cell = BasicRNNCell(hidden_size)\n",
    "    dec_cell = OutputProjectionWrapper(dec_cell, dec_vocab_size+2)\n",
    "    \n",
    "    # EmbeddingWrapper & tf.unstack(dec_inputs_t) raises dimension error\n",
    "    dec_emb_inputs = tf.nn.embedding_lookup(dec_Wemb, dec_inputs_t)\n",
    "    \n",
    "    # dec_outputs: [dec_sent_len+1 x batch_size x hidden_size]\n",
    "    dec_outputs, dec_last_state = attention_decoder(\n",
    "        decoder_inputs=tf.unstack(dec_emb_inputs),\n",
    "        initial_state=enc_last_state,\n",
    "        attention_states=attention_states,\n",
    "        cell=dec_cell,\n",
    "        loop_function=_extract_argmax_and_embed(dec_Wemb))\n",
    "\n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.argmax(tf.stack(dec_outputs), axis=-1), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  Korea Korea like Seoul _GO like like Seoul please like like\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  ! this like this this this this this this this this\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  Korea like this this like ! you ! ! you !\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  ! this like South this like ! ! like like !\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  , you this this this this this this this this this\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  Korea Korea like Seoul _GO like like Seoul please like you\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  Python you this this this this this this this this this\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  Python meet please you you you you you you you you\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 14.17\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you ! ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South . . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I brown industrial _PAD . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 1.69\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.01\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07_embedding_attention_decoder\n",
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/07_embedding_attention_decoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch_major => time_major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, [1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, [1,0])\n",
    "    \n",
    "with tf.variable_scope('encoder'):\n",
    "    enc_cell = BasicRNNCell(hidden_size)\n",
    "    enc_cell = EmbeddingWrapper(enc_cell, enc_vocab_size+1, enc_emb_size)\n",
    "    \n",
    "    # enc_sent_len x batch_size x embedding_size\n",
    "    enc_outputs, enc_last_state = tf.contrib.rnn.static_rnn(\n",
    "        cell=enc_cell,\n",
    "        inputs=tf.unstack(enc_inputs_t),\n",
    "        sequence_length=sequence_lengths,\n",
    "        dtype=tf.float32)\n",
    "\n",
    "top_states = []\n",
    "with tf.variable_scope('attention'):\n",
    "    # top_states: enc_sent_len x [batch_size x 1 x embedding_size]\n",
    "    #           list of enc_output of each encoder step\n",
    "    # enc_outputs has length of enc_sent_len (= max_enc_len)\n",
    "    for enc_output in enc_outputs:\n",
    "        top_states.append(tf.reshape(enc_output, [-1, 1, enc_cell.output_size]))\n",
    "\n",
    "    # attention_states: [batch_size x enc_sent_len x embedding_size]\n",
    "    attention_states = tf.concat(top_states, 1)\n",
    "    \n",
    "dec_outputs = []\n",
    "dec_predictions = []\n",
    "with tf.variable_scope('decoder'):\n",
    "    dec_cell = BasicRNNCell(hidden_size)\n",
    "    \n",
    "    # dec_outputs: [dec_sent_len+1 x batch_size x hidden_size]\n",
    "    dec_outputs, dec_last_state = embedding_attention_decoder(\n",
    "        decoder_inputs=tf.unstack(dec_inputs_t),\n",
    "        initial_state=enc_last_state,\n",
    "        attention_states=attention_states,\n",
    "        cell=dec_cell,\n",
    "        num_symbols=dec_vocab_size+2,\n",
    "        embedding_size=dec_emb_size)\n",
    "\n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.argmax(tf.stack(dec_outputs), axis=-1), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  I Hi Python Hi Seoul Jaemin Seoul Python to Hi _GO\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  Python Seoul live I live Python is live I live live\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  Leffe Hi Leffe Hi Bye Bye live Hi Hi Hi Hi\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  Korea Jaemin please please to brown _GO _GO _GO _GO _GO\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  this Hi Seoul Hi Hi industrial Python Hi industrial Hi Hi\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  I study I Jaemin Seoul Jaemin Seoul like Seoul Beer Beer\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  I Hi too Hi Hi Hi Hi Hi Hi Hi Hi\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  I study meet study Korea I Korea _GO _GO _GO _GO\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 14.16\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO I brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 1.54\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.05\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08_embedding_attention_seq2seq\n",
    "- https://github.com/j-min/tf_tutorial_plus/blob/master/RNN_seq2seq/legacy_seq2seq/08_embedding_attention_seq2seq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "enc_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, enc_sentence_length],\n",
    "    name='input_sentences')\n",
    "\n",
    "sequence_lengths = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None],\n",
    "    name='sentences_length')\n",
    "\n",
    "dec_inputs = tf.placeholder(\n",
    "    tf.int32,\n",
    "    shape=[None, dec_sentence_length+1],\n",
    "    name='output_sentences')\n",
    "\n",
    "# batch_major => time_major\n",
    "enc_inputs_t = tf.transpose(enc_inputs, [1,0])\n",
    "dec_inputs_t = tf.transpose(dec_inputs, [1,0])\n",
    "\n",
    "cell = BasicRNNCell(hidden_size)\n",
    "\n",
    "with tf.variable_scope(\"embedding_attention_seq2seq\"):\n",
    "    # dec_outputs: [dec_sent_len+1 x batch_size x hidden_size]\n",
    "    dec_outputs, dec_last_state = embedding_attention_seq2seq(\n",
    "        encoder_inputs=tf.unstack(enc_inputs_t),\n",
    "        decoder_inputs=tf.unstack(dec_inputs_t),\n",
    "        cell=cell,\n",
    "        num_encoder_symbols=enc_vocab_size+1,\n",
    "        num_decoder_symbols=dec_vocab_size+2,\n",
    "        embedding_size=enc_emb_size,\n",
    "        feed_previous=True)\n",
    "\n",
    "# predictions: [batch_size x dec_sentence_lengths+1]\n",
    "predictions = tf.transpose(tf.argmax(tf.stack(dec_outputs), axis=-1), [1,0])\n",
    "\n",
    "# labels & logits: [dec_sentence_length+1 x batch_size x dec_vocab_size+2]\n",
    "labels = tf.one_hot(dec_inputs_t, dec_vocab_size+2)\n",
    "logits = tf.stack(dec_outputs)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits))\n",
    "\n",
    "# training_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "training_op = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\t Hi What is your name?\n",
      "\t =>  like meet engineering meet engineering engineering this engineering engineering engineering engineering\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  industrial this this this this engineering engineering engineering engineering this engineering\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  industrial engineering this this this this engineering engineering engineering engineering this\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  industrial this this this this engineering engineering this engineering this this\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  industrial this this this this this this this this this this\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  industrial engineering this engineering engineering engineering engineering engineering engineering engineering engineering\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  industrial meet this this this this this this engineering engineering this\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  like meet like like like like like like like like like\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 14.34\n",
      "\n",
      "Epoch 400\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO I to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live Python , , South . _PAD _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 2.08\n",
      "\n",
      "Epoch 800\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.04\n",
      "\n",
      "Epoch 1200\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Epoch 1600\n",
      "\t Hi What is your name?\n",
      "\t =>  _GO Hi this is Jaemin . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Hi this is Jaemin.\n",
      "\t Nice to meet you!\n",
      "\t =>  _GO Nice to meet you too ! _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Nice to meet you too!\n",
      "\t Which programming language do you use?\n",
      "\t =>  _GO I like Python . _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I like Python.\n",
      "\t See you later.\n",
      "\t =>  _GO Bye Bye . _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Bye Bye.\n",
      "\t Where do you live?\n",
      "\t =>  _GO I live in Seoul , South Korea . _PAD _PAD\n",
      "\tCorrect answer: I live in Seoul, South Korea.\n",
      "\t What is your major?\n",
      "\t =>  _GO I study industrial engineering . _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: I study industrial engineering.\n",
      "\t What do you want to drink?\n",
      "\t =>  _GO Beer please ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Beer please!\n",
      "\t What is your favorite beer?\n",
      "\t =>  _GO Leffe brown ! _PAD _PAD _PAD _PAD _PAD _PAD _PAD\n",
      "\tCorrect answer: Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_token_indices = []\n",
    "            target_token_indices = []\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            for input_sent in input_batch:\n",
    "                input_sent, sent_len = sent2ids(input_sent, vocab=enc_word2id, max_sentence_length=enc_sentence_length)\n",
    "                input_token_indices.append(input_sent)\n",
    "                sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                target_token_indices.append(\n",
    "                    sent2ids(target_sent, vocab=dec_word2id, max_sentence_length=dec_sentence_length, is_target=True))\n",
    "            \n",
    "            # Evaluate three operations in the graph\n",
    "            # => predictions, loss, training_op(optimzier)\n",
    "            batch_preds, batch_loss, _ = sess.run(\n",
    "                [predictions, loss, training_op],\n",
    "                feed_dict={\n",
    "                    enc_inputs: input_token_indices,\n",
    "                    sequence_lengths: sentence_lengths,\n",
    "                    dec_inputs: target_token_indices\n",
    "                })\n",
    "            loss_history.append(batch_loss)\n",
    "            epoch_loss += batch_loss\n",
    "            all_preds.append(batch_preds)\n",
    "            \n",
    "        # Logging every 400 epochs\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                    print('\\t', input_sent)\n",
    "                    print('\\t => ', ids2sent(pred, reverse_vocab=dec_id2word))\n",
    "                    print('\\tCorrect answer:', target_sent)\n",
    "            print('\\tepoch loss: {:.2f}\\n'.format(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
